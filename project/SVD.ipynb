{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/08 11:26:48 WARN Utils: Your hostname, jupyter resolves to a loopback address: 127.0.1.1; using 172.16.199.17 instead (on interface eth0)\n",
      "22/02/08 11:26:48 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/02/08 11:26:49 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/02/08 11:26:51 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- [('spark.sql.warehouse.dir', 'file:/home/user1/jupyter/MassiveDataAnalytics/project/spark-warehouse'), ('spark.executor.id', 'driver'), ('spark.app.name', 'Spark_Processor'), ('spark.driver.host', '172.16.199.17'), ('spark.executor.memory', '64g'), ('spark.app.startTime', '1644319609594'), ('spark.driver.memory', '64g'), ('spark.rdd.compress', 'True'), ('spark.serializer.objectStreamReset', '100'), ('spark.master', 'local[*]'), ('spark.submit.pyFiles', ''), ('spark.driver.port', '46397'), ('spark.submit.deployMode', 'client'), ('spark.app.id', 'local-1644319611673'), ('spark.ui.showConsoleProgress', 'true')]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType,TimestampType\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Spark_Processor\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "schema = StructType([ \\\n",
    "        StructField(\"DEVICE_CODE\", IntegerType(), True), \n",
    "        StructField(\"SYSTEM_ID\",IntegerType(),True), \\\n",
    "        StructField(\"ORIGINE_CAR_KEY\",IntegerType(),True), \\\n",
    "        StructField(\"FINAL_CAR_KEY\", IntegerType(),True), \\\n",
    "        StructField(\"CHECK_STATUS_KEY\", IntegerType(), True), \\\n",
    "        StructField(\"COMPANY_ID\", StringType(), True), \\\n",
    "        StructField(\"PASS_DAY_TIME\", TimestampType(), True)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+---------------+-------------+----------------+----------+-------------------+\n",
      "|DEVICE_CODE|SYSTEM_ID|ORIGINE_CAR_KEY|FINAL_CAR_KEY|CHECK_STATUS_KEY|COMPANY_ID|      PASS_DAY_TIME|\n",
      "+-----------+---------+---------------+-------------+----------------+----------+-------------------+\n",
      "|     200501|       81|       10477885|     10477885|               5|       161|2021-06-01 03:54:39|\n",
      "|        155|       81|       87625017|     87625017|               5|       161|2021-06-01 04:14:21|\n",
      "|     631757|       81|        8652928|      8652928|               5|       161|2021-06-01 03:58:57|\n",
      "|     631757|       81|        8548123|      8548123|               5|       161|2021-06-01 04:01:38|\n",
      "|     631757|       81|       24715264|     24715264|               5|       161|2021-06-01 03:56:57|\n",
      "+-----------+---------+---------------+-------------+----------------+----------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('Traffic.csv',header=True,schema=schema)\n",
    "df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import dayofyear\n",
    "df = df.withColumn('day', dayofyear(df.PASS_DAY_TIME))\n",
    "df = df.filter(df.day != 159)\n",
    "df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:====================================================>   (15 + 1) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all count:  34989160\n",
      "car count:  5487645\n",
      "camera count:  1035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "DATA_COUNT = df.count()\n",
    "CAR_COUNT = df.select('FINAL_CAR_KEY').distinct().count()\n",
    "CAMERA_COUNT = df.select('DEVICE_CODE').distinct().count()\n",
    "print('all count: ', DATA_COUNT)\n",
    "print('car count: ', CAR_COUNT)\n",
    "print('camera count: ', CAMERA_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 190:================================>                     (15 + 10) / 25]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+\n",
      "|FINAL_CAR_KEY|  count|\n",
      "+-------------+-------+\n",
      "|     64111706|1891912|\n",
      "|     69177480|  80818|\n",
      "|      8073331|  30194|\n",
      "|     67682391|   6227|\n",
      "|      7633319|   1579|\n",
      "|     14919817|   1513|\n",
      "|     19516092|   1385|\n",
      "|      8396536|    804|\n",
      "|     73138295|    730|\n",
      "|     23975824|    550|\n",
      "+-------------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "car_counts = df.groupBy('FINAL_CAR_KEY').count()\n",
    "car_counts.sort('count', ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_cars = car_counts.filter(car_counts['count'] < 1000).sort('count', ascending=False).select('FINAL_CAR_KEY').take(100)\n",
    "traffic_cars = [x.FINAL_CAR_KEY for x in traffic_cars]\n",
    "top_cars_df = df.filter(df.FINAL_CAR_KEY.isin(traffic_cars))\n",
    "top_cars_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "36907"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOP_CARS_RECORDS = top_cars_df.count()\n",
    "TOP_CARS_RECORDS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 26:====================================================>   (15 + 1) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-----+\n",
      "|DEVICE_CODE|FINAL_CAR_KEY|count|\n",
      "+-----------+-------------+-----+\n",
      "|     631367|      8642668|    6|\n",
      "|     631357|     13565906|   16|\n",
      "|     900249|     11054045|   14|\n",
      "|     900237|     17890990|   21|\n",
      "|     631829|     11054045|    6|\n",
      "+-----------+-------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "camera_car_df = top_cars_df.groupBy('DEVICE_CODE', 'FINAL_CAR_KEY').count()\n",
    "camera_car_df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 41:==============>                                         (4 + 12) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-----+---------+------------+\n",
      "|DEVICE_CODE|FINAL_CAR_KEY|count|CAR_INDEX|CAMERA_INDEX|\n",
      "+-----------+-------------+-----+---------+------------+\n",
      "|        135|     11086409|    1|      3.0|       139.0|\n",
      "|     213301|     25826200|    1|      6.0|       226.0|\n",
      "|        144|      8556436|    2|     40.0|        90.0|\n",
      "|     202601|      8137760|    2|     37.0|        45.0|\n",
      "|   22010087|      7633319|    7|      0.0|       234.0|\n",
      "+-----------+-------------+-----+---------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "camera_car_indexed_df = StringIndexer(inputCol='FINAL_CAR_KEY', outputCol='CAR_INDEX').fit(camera_car_df).transform(camera_car_df)\n",
    "camera_car_indexed_df = StringIndexer(inputCol='DEVICE_CODE', outputCol='CAMERA_INDEX').fit(camera_car_indexed_df).transform(camera_car_indexed_df)\n",
    "camera_car_indexed_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.linalg.distributed import CoordinateMatrix\n",
    "utility_matrix = CoordinateMatrix(camera_car_indexed_df.rdd.map(lambda x: (int(x['CAR_INDEX']), int(x['CAMERA_INDEX']), x['count']) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/06 08:58:56 WARN RowMatrix: The input data is not directly cached, which may hurt performance if its parent RDDs are also uncached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[505.0079430191521,448.4295807359056,234.00214006863334,179.1701725920204,164.08997913184254,128.8791269976936,89.96735321905756,85.39518265895747,81.27830846566535,73.68298955156429,71.16152478824884,63.00000000000001,54.67770373301821,50.08082000595019,46.65059215674066,40.75131283041665,39.49700737544456,38.81535112797081,37.883517887572744,37.477208085831876,36.48712513043299,34.10351087756282,32.95191581964757,31.668219074999598,29.382353059741757,28.007321050538476,27.81619066292238,27.173428229890284,25.9063839257756,25.51413614576888,24.916241572216165,24.226667981846077,24.030657094981326,23.365738603258077,19.73522502525707,18.44050839391655,17.983228407353685,17.882637049599147,17.512933811166867,16.650162052423365,16.219922944230152,15.917728847396386,15.32284427560125,14.385998218746812,13.55772093864274,12.77531198470423,12.033550152122068,11.946000054777999,11.341697289372854,11.021451077725494,10.16109555211842,9.735261830759898,9.507578905362777,9.188825793668242,8.823958880996985,8.485863804773336,8.254206275227316,8.007958267734322,7.805458990250793,7.568169484083738,7.435108817860928,7.216410472901462,7.150614541934764,6.957017095677734,6.749830791402377,6.61452118027757,6.1224956990849195,5.9517118327099725,5.900083920777868,5.746792736979727,5.578515795679902,5.488189150992062,5.245580589257855,5.15945685037778,5.002752861010993,4.729706548271054,4.575612726085403,4.489169245076955,4.380431574230309,4.2591345871274555,4.186316332851386,3.9698751603389435,3.881254514451058,3.4001644698999587,2.9255674135050587,2.54326438597946,2.304989610182516,2.203391628481175,2.0919433490984125,1.9827498863351767,1.9701205203426122,1.8324460956934092,1.46841830859159,1.3164258674620943,0.9580622771896989,0.8676980392236744,0.6278051866889065,0.36411018126454153]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/06 08:59:06 WARN RowMatrix: Requested 100 singular values but only found 98 nonzeros.\n",
      "22/02/06 08:59:06 WARN RowMatrix: The input data was not directly cached, which may hurt performance if its parent RDDs are also uncached.\n"
     ]
    }
   ],
   "source": [
    "svd = utility_matrix.toRowMatrix().computeSVD(100, computeU=True)\n",
    "print(svd.s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(utility_matrix.numCols())\n",
    "print(utility_matrix.numRows())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae917f7814ccb34d4acac350c21a9b5c6bba089bcf202fb1054d30d044271271"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('HW-QXNApxFg': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
